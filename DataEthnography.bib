@book{chunDiscriminatingDataCorrelation2021a,
  title = {Discriminating {{Data}}: {{Correlation}}, {{Neighborhoods}}, and the {{New Politics}} of {{Recognition}}},
  shorttitle = {Discriminating {{Data}}},
  author = {Chun, Wendy Hui Kyong},
  year = {2021},
  month = nov,
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  abstract = {How big data and machine learning encode discrimination and create agitated clusters of comforting rage.In Discriminating Data, Wendy Hui Kyong Chun reveals how polarization is a goal\textemdash not an error\textemdash within big data and machine learning. These methods, she argues, encode segregation, eugenics, and identity politics through their default assumptions and conditions. Correlation, which grounds big data's predictive potential, stems from twentieth-century eugenic attempts to ``breed'' a better future. Recommender systems foster angry clusters of sameness through homophily. Users are ``trained'' to become authentically predictable via a politics and technology of recognition. Machine learning and data analytics thus seek to disrupt the future by making disruption impossible.~Chun, who has a background in systems design engineering as well as media studies and cultural theory, explains that although machine learning algorithms may not officially include race as a category, they embed whiteness as a default. Facial recognition technology, for example, relies on the faces of Hollywood celebrities and university undergraduates\textemdash groups not famous for their diversity. Homophily emerged as a concept to describe white U.S. resident attitudes to living in biracial yet segregated public housing. Predictive policing technology deploys models trained on studies of predominantly underserved neighborhoods. Trained on selected and often discriminatory or dirty data, these algorithms are only validated if they mirror this data.~~How can we release ourselves from the vice-like grip of discriminatory data? Chun calls for alternative algorithms, defaults, and interdisciplinary coalitions in order to desegregate networks and foster a more democratic big data.},
  collaborator = {Barnett, Alex},
  isbn = {978-0-262-04622-0},
  langid = {english}
}

@book{lamdanDataCartelsCompanies2022,
  title = {Data {{Cartels}}: {{The Companies That Control}} and {{Monopolize Our Information}}},
  shorttitle = {Data {{Cartels}}},
  author = {Lamdan, Sarah},
  year = {2022},
  month = nov,
  edition = {1st edition},
  publisher = {{Stanford University Press}},
  address = {{Stanford, California}},
  abstract = {In our digital world, data is power. Information hoarding businesses reign supreme, using intimidation, aggression, and force to maintain influence and control. Sarah Lamdan brings us into the unregulated underworld of these "data cartels", demonstrating how the entities mining, commodifying, and selling our data and informational resources perpetuate social inequalities and threaten the democratic sharing of knowledge. Just a few companies dominate most of our critical informational resources. Often self-identifying as "data analytics" or "business solutions" operations, they supply the digital lifeblood that flows through the circulatory system of the internet. With their control over data, they can prevent the free flow of information, masterfully exploiting outdated information and privacy laws and curating online information in a way that amplifies digital racism and targets marginalized communities. They can also distribute private information to predatory entities. Alarmingly, everything they're doing is perfectly legal. In this book, Lamdan contends that privatization and tech exceptionalism have prevented us from creating effective legal regulation. This in turn has allowed oversized information oligopolies to coalesce. In addition to specific legal and market-based solutions, Lamdan calls for treating information like a public good and creating digital infrastructure that supports our democratic ideals.},
  isbn = {978-1-5036-3371-1},
  langid = {english}
}
